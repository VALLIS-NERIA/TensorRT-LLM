pytorch_backend_config:
    use_cuda_graph: true
    cuda_graph_padding_enabled: true
    cuda_graph_batch_sizes:
    - 1
    - 2
    - 4
    - 8
    - 16
    - 32
    - 64
    print_iter_log: true
    enable_overlap_scheduler: true
    moe_max_num_tokens: 256
enable_attention_dp: true
# speculative_config:
#     decoding_type: MTP
#     num_nextn_predict_layers: 3
